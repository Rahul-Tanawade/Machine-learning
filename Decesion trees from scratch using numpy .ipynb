{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GITHUB DECESION TRESS.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMcvUCkiHumG/WuQF2bZdBU"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jk87K7mDea_",
        "outputId": "cbbfc77b-6ee6-40e3-b643-9af823581c59"
      },
      "source": [
        "#decison trees for sklearn\n",
        "\n",
        "import numpy  as np\n",
        "from collections import Counter\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def entropy(y):\n",
        "    hist=np.bincount(y)\n",
        "    ps = hist /len(y)\n",
        "    return   -np.sum([p*np.log2(p) for p in ps if p > 0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class node:\n",
        "    def __init__(self,feature=None, threshold=None,left=None,right=None,*,value=None):\n",
        "        self.feature=feature\n",
        "        self.threshold=threshold\n",
        "        self.left=left\n",
        "        self.right=right\n",
        "        self.value=value\n",
        "        \n",
        "    def is_leaf_node(self):\n",
        "      return self.value is not None\n",
        "\n",
        "class DecisonTree:\n",
        "    def __init__(self,min_samples_split=2,max_depth=100,n_feats=None):\n",
        "        self.min_samples_split=min_samples_split\n",
        "        self.max_depth=max_depth\n",
        "        self.n_feats=n_feats\n",
        "        self.root=None\n",
        "\n",
        "\n",
        "    def fit(self,X,y):\n",
        "      #grow tree\n",
        "      self.n_feats= X.shape[1] if not self.n_feats else min (self.n_feats,X.shape[1])\n",
        "      self.root= self._grow_tree(X,y)\n",
        "      \n",
        "    def _grow_tree(self,X,y,depth=0):\n",
        "        n_samples,n_features=X.shape\n",
        "        n_labels=len(np.unique(y))\n",
        "        \n",
        "        #stoping criteria\n",
        "        if (depth >=self.max_depth\n",
        "            or n_labels==1\n",
        "            or n_samples < self.min_samples_split):\n",
        "            \n",
        "            leaf_value=self._most_common_label(y)\n",
        "            return node(value=leaf_value)\n",
        "        \n",
        "       #no stopping criteria\n",
        "        feat_idxs=np.random.choice(n_features,self.n_feats,replace=False)\n",
        "       \n",
        "       #greedy search\n",
        "        best_feat,best_thresh=self._best_criteria(X,y,feat_idxs)\n",
        "        left_idx, right_idx=self._split(X[:,best_feat],best_thresh)\n",
        "        left=self._grow_tree(X[left_idx,:], y[left_idx],depth+1)\n",
        "        right=self._grow_tree(X[right_idx,:], y[right_idx],depth+1)\n",
        "        \n",
        "        return node(best_feat,best_thresh,left,right)\n",
        "    \n",
        "    def predict(self,X):\n",
        "          return np.array([self._traverse_tree(x, self.root) for x in X])\n",
        "    \n",
        "    def _traverse_tree(self,x,node):\n",
        "      #  print(\"predicting\")\n",
        "       # print(\"thresold\",node.threshold)\n",
        "       # print(\"feature\",x[node.feature])\n",
        "        \n",
        "        if node.is_leaf_node():\n",
        "            return node.value\n",
        "        \n",
        "        if x[node.feature] <= node.threshold:\n",
        "            return self._traverse_tree(x,node.left)\n",
        "        return self._traverse_tree(x, node.right)\n",
        "    \n",
        "    \n",
        "    def _best_criteria(self,X,y,feat_idxs):\n",
        "        best_gain=-1\n",
        "        split_idx,split_thresh=None,None\n",
        "        \n",
        "        for feat_idx in feat_idxs:\n",
        "            X_column=X[:,feat_idx]\n",
        "            thresholds=np.unique(X_column)\n",
        "            \n",
        "            for threshold in thresholds:\n",
        "                gain=self._information_gain(y,X_column,threshold)\n",
        "                \n",
        "                if gain > best_gain:\n",
        "                    best_gain=gain\n",
        "                    split_idx=feat_idx\n",
        "                    split_thresh=threshold\n",
        "        return split_idx,split_thresh\n",
        "   \n",
        "    def _information_gain(self,y,X_column,split_thresh):\n",
        "        #parent entropy\n",
        "        parent_entropy=entropy(y)\n",
        "        \n",
        "        \n",
        "        #generate split\n",
        "        left_idx,right_idx=self._split(X_column,split_thresh)\n",
        "        \n",
        "        if len(left_idx)==0 or len(right_idx)==0:\n",
        "            return 0\n",
        "        n=len(y)\n",
        "        n_l,n_r=len(left_idx),len(right_idx)\n",
        "        e_l,e_r=entropy(y[left_idx]),entropy(y[right_idx])\n",
        "        child_entropy=(n_l/n)*e_l + (n_r/n)*e_r\n",
        "\n",
        "        ig=parent_entropy-child_entropy\n",
        "        return ig\n",
        "    \n",
        "    \n",
        "    def _most_common_label(self,y):\n",
        "        counter=Counter(y)\n",
        "        most_common=counter.most_common(1)[0][0]\n",
        "        return most_common\n",
        "    \n",
        "        \n",
        "    \n",
        "    def _split(self,X_column,split_thresh):\n",
        "      left_idxs = np.argwhere(X_column <=split_thresh).flatten()\n",
        "      right_idxs = np.argwhere(X_column >split_thresh).flatten() \n",
        "      return left_idxs,right_idxs\n",
        "  \n",
        "def accuracy(y_true, y_pred):\n",
        "     \n",
        "     accuracy = np.sum(y_true == y_pred) / len(y_true)\n",
        "     return accuracy    \n",
        "\n",
        "if __name__ == \"__main__\" :\n",
        "    \n",
        "    data=datasets.load_breast_cancer()\n",
        "    X=data.data\n",
        "    y=data.target\n",
        "    \n",
        "    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=12)\n",
        "    \n",
        "    d=DecisonTree(max_depth=10)\n",
        "    \n",
        "    d.fit(X_train,y_train)\n",
        "    print(d.root.__dict__)\n",
        "    y_pred=d.predict(X_test)\n",
        "   \n",
        "       \n",
        "    print(\"checking accuracy\")\n",
        "    acc = accuracy(y_test, y_pred)\n",
        "    print (\"Accuracy:\", acc)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'feature': 20, 'threshold': 16.77, 'left': <__main__.node object at 0x7f17c86232d0>, 'right': <__main__.node object at 0x7f17c86236d0>, 'value': None}\n",
            "checking accuracy\n",
            "Accuracy: 0.9473684210526315\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}